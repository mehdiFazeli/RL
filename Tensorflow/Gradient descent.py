# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-jQWlI7NWSENR8DzpY7MjFzeEEeBgSjc
"""

import numpy as np

observations = 1000
xs = np.random.uniform(-10, 10, (observations, 1))
zs = np.random.uniform(-10, 10, (observations, 1))
inputs = np.column_stack((xs, zs))
print (inputs.shape)

# 2 * x + 3 * z + 5 + noise
W = np.array([2, 3])
noise = np.random.uniform(-1, 1, (observations, 1))
targets = 2 * xs + 3 * zs + noise
print (targets.shape)

init_range = 0.1

wheights = np.random.uniform(-init_range, init_range, (2, 1))
biases = np.random.uniform(-init_range, init_range, size = 1)

print (wheights.shape)
print (biases.shape)

learning_rate = 0.002

Ws = np.copy(wheights)
Bs = np.copy(biases)

for i in range(20):
  outputs = np.dot(inputs, Ws)  + Bs
  deltas = outputs -  targets

  loss = np.sum(deltas ** 2) / 2 / observations

  print (i,lr, loss)

  deltas_scaled = deltas / observations
  Ws = Ws - learning_rate * np.dot(inputs.T, deltas_scaled)
  Bs = Bs - learning_rate * np.sum(deltas_scaled)